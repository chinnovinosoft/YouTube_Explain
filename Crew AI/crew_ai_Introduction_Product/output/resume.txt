```
John Doe
(123) 456-7890 | johndoe@example.com
linkedin.com/in/johndoe | github.com/johndoe

Summary
Results-driven Data Engineer with 5 years of experience in designing and implementing scalable data pipelines and architectures. Proficient in optimizing ETL processes and enhancing data quality, with a strong focus on data-driven decision-making.

Technical Skills
- Programming Languages: Python, SQL, Java
- Data Technologies: Apache Spark, Apache Kafka, Apache Airflow, Apache NiFi
- Databases: PostgreSQL, Amazon Redshift, MongoDB, Google BigQuery
- Cloud Platforms: AWS (S3, EMR, Lambda), Microsoft Azure
- Development Tools: Docker, Kubernetes, Git
- BI Tools: Tableau, Looker

Professional Experience
Data Engineer | ABC Corp | New York, NY | Jan 2020 - Present
- Developed and maintained ETL pipelines utilizing Apache Airflow and Python, processing over 10TB of data daily to support business intelligence initiatives.
- Collaborated with data scientists to optimize data accessibility by implementing data warehousing solutions using Amazon Redshift.
- Established and led a data governance framework ensuring compliance, accuracy, and security of data systems.
- Implemented monitoring and alerting solutions for ETL processes to ensure minimal downtime and reliable data flow.

Junior Data Engineer | XYZ Inc | Boston, MA | Jan 2018 - Dec 2019
- Assisted in designing and building data models in PostgreSQL, which enhanced data retrieval speeds by 30%.
- Automated data ingestion processes from MongoDB to AWS S3 using Apache Kafka, significantly improving data availability.
- Participated in analytics projects to visualize data trends implementing business intelligence tools, resulting in actionable insights for stakeholders.

Projects
Project 1: Real-time Data Processing Pipeline
- Developed a real-time data pipeline using Apache Kafka and Spark Streaming to process IoT sensor data for a smart home application.
- Achieved sub-second latency in processing incoming data streams, enabling real-time analytics and alerts for users.

Project 2: Data Warehouse Optimization
- Architected a data warehouse solution on Amazon Redshift for a retail company, resulting in a 50% decrease in query runtime after implementing proper indexing and data partitioning techniques.
- Created automated ETL workflows using Apache Airflow for accurate and timely data updates.

Education
B.S. in Computer Science | University of Technology | Graduated May 2017
```